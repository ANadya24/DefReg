{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "326bd476-9e53-455d-88ce-70ef3d3abd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c65ed84d-218f-41e0-a618-219ba10c9051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 5, 7])\n"
     ]
    }
   ],
   "source": [
    "m = nn.AdaptiveAvgPool2d((5,7))\n",
    "input = torch.randn(1, 64, 8, 9)\n",
    "output = m(input)\n",
    "print(output.shape)\n",
    "# >>> # target output size of 7x7 (square)\n",
    "# >>> m = nn.AdaptiveAvgPool2d(7)\n",
    "# >>> input = torch.randn(1, 64, 10, 9)\n",
    "# >>> output = m(input)\n",
    "# >>> # target output size of 10x7\n",
    "# >>> m = nn.AdaptiveAvgPool2d((None, 7))\n",
    "# >>> input = torch.randn(1, 64, 10, 9)\n",
    "# >>> output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e70129d1-d49a-4a02-a09a-3dfe2b110247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "m = nn.AdaptiveAvgPool2d((1,1))\n",
    "input = torch.randn(1, 64, 8, 9)\n",
    "output = m(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b5aa5f-fd8a-49cf-bcea-90de3cb780ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8231535-db8c-444f-b802-bfa2e039e671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ea936f4-0b4d-4a1a-a383-ea88a94a2db0",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c01e92f-bc95-4d5f-a294-530485dfd38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils import data\n",
    "from skimage.transform import resize\n",
    "from skimage import io, color\n",
    "from scipy import io as spio\n",
    "import pickle\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from utils.ffRemap import *\n",
    "from utils.data_process import pad_image, match_histograms, normalize_min_max, normalize_mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d727009e-b3fb-4301-8bd1-a54f9fc81622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba4ae469-5c0e-4902-9b38-f70c42145087",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, image_sequences, image_keypoints,\n",
    "                 im_size=(1, 256, 256),\n",
    "                 train=True, shuffle=False, register_limit=5,\n",
    "                 use_masks=True, use_crop=False):\n",
    "        \"\"\"\n",
    "        \n",
    "        :param: image_sequences:\n",
    "        :param: image_keypoints:\n",
    "        :param: im_size:\n",
    "        :param: train:\n",
    "        :param: register_limit:\n",
    "        :param: shuffle:\n",
    "        :param: use_masks:\n",
    "        :param: use_crop:\n",
    "        \"\"\"\n",
    "        self.image_sequences = []\n",
    "        self.image_keypoints = []\n",
    "        \n",
    "        for sequence_path, keypoint_path in zip(image_sequences, image_keypoints):\n",
    "            assert sequence_path.split('/')[-1].split('.')[0] == \\\n",
    "            keypoint_path.split('/')[-1].split('.')[0], 'Keypoint and sequence files must be ordered!'\n",
    "            \n",
    "            seq = io.imread(sequence_path)\n",
    "            print('len(seq)', len(seq))\n",
    "            print(seq[0].dtype, seq[0].max())\n",
    "            if seq.shape[-1] == 3:\n",
    "                seq = color.rgb2gray(seq)\n",
    "                print(seq[0].dtype, seq[0].max())\n",
    "            self.image_sequences.append(seq)\n",
    "            \n",
    "            poi = spio.loadmat(keypoint_path)\n",
    "            bound = np.stack(poi['spotsB'][0].squeeze())\n",
    "            inner = np.stack(poi['spotsI'][0].squeeze())\n",
    "\n",
    "            bound = bound[:, :, :2]\n",
    "            inner = inner[:, :, :2]\n",
    "\n",
    "            line1 = np.stack(poi['lines'][:, 0])\n",
    "            line2 = np.stack(poi['lines'][:, 1])\n",
    "            line3 = np.stack(poi['lines'][:, 2])\n",
    "            line4 = np.stack(poi['lines'][:, 3])\n",
    "\n",
    "            len1 = len(line1[0])\n",
    "            len2 = len(line2[0])\n",
    "            len3 = len(line3[0])\n",
    "            len4 = len(line4[0])\n",
    "\n",
    "            lines = np.concatenate((line1, line2, line3, line4), axis=1)\n",
    "            lines_lengths = np.array([len1, len2, len3, len4])\n",
    "            self.image_keypoints.append({'inner': inner, 'bound': bound, 'lines': (lines, lines_lengths)})\n",
    "            \n",
    "            \n",
    "            \n",
    "        # with open(path, 'rb') as file:\n",
    "        #     self.data = pickle.load(file)\n",
    "        #     print(self.data.keys())\n",
    "        # if use_masks:\n",
    "        #     with open(path.split('.pkl')[0] + '_body.pkl', 'rb') as file:\n",
    "        #         self.masks = pickle.load(file)\n",
    "        #         print(self.masks.keys())\n",
    "\n",
    "        self.length = sum([len(sequence) for sequence in self.image_sequences])\n",
    "        print('Dataset length is ', self.length)\n",
    "        self.seq_numeration = []\n",
    "\n",
    "        for seq_idx, _ in enumerate(self.image_sequences):\n",
    "            for i, _ in enumerate(self.image_sequences):\n",
    "                self.seq_numeration.append((seq_idx, i))\n",
    "\n",
    "        self.use_masks = use_masks\n",
    "        self.use_crop = use_crop\n",
    "        \n",
    "        self.im_size = im_size[1:]\n",
    "        self.train = train\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        if isinstance(register_limit, int):\n",
    "            self.register_limit = [register_limit] * len(self.image_sequences)\n",
    "        else:\n",
    "            assert len(register_limit) == len(self.image_sequences), 'limit value must be assigned either \\\n",
    "            by integer or by the list of values for each mage sequenceaccordingly'\n",
    "            \n",
    "            self.register_limit = register_limit\n",
    "        \n",
    "        \n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.seq_numeration)\n",
    "#         TODO add aug\n",
    "#         if self.train:\n",
    "#             self.aug_pipe = A.Compose([A.HorizontalFlip(p=1),# A.VerticalFlip(p=0.3),\n",
    "#                                   #A.ShiftScaleRotate(shift_limit=0.0225, scale_limit=0.1, rotate_limit=15, p=0.2)\n",
    "#                                   ], additional_targets={'image2': 'image', 'keypoints2': 'keypoints'},\n",
    "#                                       keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "        \n",
    "        self.to_tensor = ToTensor()\n",
    "        self.resize = A.Compose([A.Resize(*self.im_size)],\n",
    "                                keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        seq_idx, it = self.seq_numeration[index]\n",
    "        current_seq_len = len(self.image_sequences[seq_idx])\n",
    "        \n",
    "        if self.train:\n",
    "            it2 = np.random.randint(max(it-self.register_limit[seq_idx], 0),\n",
    "                                    min(it+self.register_limit[seq_idx] + 1, current_seq_len - 1), size=1)\n",
    "        else:\n",
    "            it2 = min(it + 1, current_seq_len - 1)\n",
    "\n",
    "        image1 = self.image_sequences[seq_idx][it].squeeze()\n",
    "        image2 = self.image_sequences[seq_idx][it2].squeeze()\n",
    "        \n",
    "        inner1 = self.image_keypoints[seq_idx]['inner'][it]\n",
    "        inner2 = self.image_keypoints[seq_idx]['inner'][it2]\n",
    "        bound1 = self.image_keypoints[seq_idx]['bound'][it]\n",
    "        bound2 = self.image_keypoints[seq_idx]['bound'][it2]\n",
    "        lines1 = self.image_keypoints[seq_idx]['lines'][0][it]\n",
    "        lines_len = self.image_keypoints[seq_idx]['lines'][1]\n",
    "        lines2 = self.image_keypoints[seq_idx]['lines'][0][it2]\n",
    "        \n",
    "        image1 = normalize_mean_std(image1)\n",
    "        image2 = normalize_mean_std(image2)\n",
    "        \n",
    "        print(image1.shape, image2.shape)\n",
    "        image1, image2 = match_histograms(image1, image2, random_switch=self.train)\n",
    "        h, w = image1.shape\n",
    "        \n",
    "        if self.use_crop:\n",
    "            x0 = np.random.randint(0, w - self.im_size[1])\n",
    "            y0 = np.random.randint(0, h - self.im_size[0])\n",
    "            image1 = image1[y0: y0 + self.im_size[0], x0:x0 + self.im_size[1]]\n",
    "            image2 = image2[y0: y0 + self.im_size[0], x0:x0 + self.im_size[1]]\n",
    "            inner1 -= np.array([x0, y0]).reshape(1, 2)\n",
    "            inner2 -= np.array([x0, y0]).reshape(1, 2)\n",
    "            bound1 -= np.array([x0, y0]).reshape(1, 2)\n",
    "            bound2 -= np.array([x0, y0]).reshape(1, 2)\n",
    "            lines1[0] -= np.array([x0, y0]).reshape(1, 2)\n",
    "            lines2[0] -= np.array([x0, y0]).reshape(1, 2)\n",
    "        else:\n",
    "            if h < w:\n",
    "                image1 = pad_image(image1, (0, w - h, 0, 0))\n",
    "                image2 = pad_image(image2, (0, w - h, 0, 0))\n",
    "            else:\n",
    "                image1 = pad_image(image1, (0, 0, 0, h - w))\n",
    "                image2 = pad_image(image2, (0, 0, 0, h - w))\n",
    "            \n",
    "            inner_len1 = len(inner1)\n",
    "            bound_len1 = len(bound1)\n",
    "            points_len = np.array([inner_len1, bound_len1, *lines_len])\n",
    "            points1 = np.concatenate([inner1, bound1, lines1], axis=0)\n",
    "            data1 = self.resize(image=image1, keypoints=points1)\n",
    "            image1, points1 =  data1['image'], np.array(data1['keypoints'])\n",
    "            \n",
    "            inner_len2 = len(inner2)\n",
    "            \n",
    "            bound_len2 = len(bound2)\n",
    "            assert inner_len2 == inner_len1\n",
    "            assert bound_len2 == bound_len1\n",
    "            \n",
    "            points2 = np.concatenate([inner2, bound2, lines2], axis=0)\n",
    "            data2 = self.resize(image=image1, keypoints=points1)\n",
    "            image2, points2 =  data2['image'], np.array(data2['keypoints'])\n",
    "\n",
    "        if self.train:\n",
    "            if np.random.rand() < 0.5:\n",
    "                image1 = image1[:, ::-1].copy()\n",
    "                image2 = image2[:, ::-1].copy()\n",
    "                points1[:, 0] = self.im_size[1] - points1[:, 0]\n",
    "                points2[:, 0] = self.im_size[1] - points2[:, 0]\n",
    "                \n",
    "\n",
    "            if np.random.rand() < 0.5:\n",
    "                image1 = image1[::-1].copy()\n",
    "                image2 = image2[::-1].copy()\n",
    "                points1[:, 1] = self.im_size[0] - points1[:, 1]\n",
    "                points2[:, 1] = self.im_size[0] - points2[:, 1]\n",
    "             \n",
    "        image1 = self.to_tensor(image1).float()\n",
    "        image2 = self.to_tensor(image2).float()\n",
    "        \n",
    "        # points1[:, 0] /= self.im_size[1]\n",
    "        # points1[:, 1] /= self.im_size[0]\n",
    "        # points2[:, 0] /= self.im_size[1]\n",
    "        # points2[:, 1] /= self.im_size[0]\n",
    "        \n",
    "        print(image1.max(), image1.min())\n",
    "        \n",
    "        return image1, image2, points1, points2, points_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "377a7fb5-8c12-48e9-abab-b8cac8ed61b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(seq) 42\n",
      "uint8 173\n",
      "Dataset length is  42\n",
      "(356, 287) (356, 287)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3379484/161700089.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'./data/SeqB/SeqB1.tif'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'./data/SeqB/SeqB1.mat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimage1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3379484/4041660164.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mbound_len2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0minner_len2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minner_len1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mbound_len2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbound_len1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = Dataset(['./data/SeqB/SeqB1.tif'], ['./data/SeqB/SeqB1.mat'], train=True)\n",
    "\n",
    "image1, image2, points1, points2, total_len = dataset[0]\n",
    "\n",
    "print(points1.shape, points2.shape)\n",
    "\n",
    "image1 = image1.numpy().squeeze()\n",
    "image2 = image2.numpy().squeeze()\n",
    "points2[:, 0] += dataset.im_size[0]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(np.concatenate([image1, image2], 1))\n",
    "plt.scatter(points1[:, 0], points1[:, 1])\n",
    "plt.scatter(points2[:, 0], points2[:, 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2753b1a2-3cac-4bd6-9f98-894eb764437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    path = '/data/sim/Notebooks/VM/dataset/train_set.pkl'\n",
    "    dataset = Dataset(path, (1, 256, 256), size_file='../src_old/sizes.txt',\n",
    "                      smooth=True, train=True, shuffle=True, use_masks=True, use_mul=False)\n",
    "    fixed, moving, deform = dataset[0]\n",
    "#    fixed = fixed[0][None]\n",
    "#    moving = moving[0][None]\n",
    "    # deform *= 10.\n",
    "    print(deform.min(), deform.max())\n",
    "    from voxelmorph2d import SpatialTransformation\n",
    "\n",
    "    SP = SpatialTransformation()\n",
    "    print(deform.shape, moving.shape)\n",
    "#    plt.imshow(np.concatenate([deform[0], deform[1]], axis=1), cmap='gray')\n",
    "#    plt.waitforbuttonpress()\n",
    "    cv2.imwrite('test0.jpg', np.concatenate([deform[0], deform[1]], axis=1))\n",
    "    movingN = SP(moving[None, :, :, :], deform[None])\n",
    "    movingN = np.uint8(movingN.numpy() * 255).squeeze()\n",
    "    print(movingN.shape)\n",
    "    fixed = np.uint8(fixed.numpy().squeeze() * 255)\n",
    "    moving = np.uint8(moving.numpy().squeeze() * 255)\n",
    "\n",
    "    print(fixed.shape, moving.shape, deform.shape)\n",
    "    print(fixed.max())\n",
    "#    plt.imshow(np.stack([fixed, moving, np.zeros(fixed.shape, dtype='int')], axis=-1), cmap='gray')\n",
    "#    plt.waitforbuttonpress()\n",
    "    cv2.imwrite('test1.jpg', np.stack([fixed[0], moving[0], np.zeros(fixed[0].shape, dtype='int')], axis=-1))\n",
    "    cv2.imwrite('masktest1.jpg', np.stack([fixed[1], moving[1], np.zeros(fixed[1].shape, dtype='int')], axis=-1))\n",
    "\n",
    "#    plt.figure()\n",
    "#    plt.imshow(np.stack([fixed, movingN, np.zeros(fixed.shape, dtype='int')], axis=-1), cmap='gray')\n",
    "#    plt.waitforbuttonpress()\n",
    "#    plt.close()\n",
    "\n",
    "    cv2.imwrite('test2.jpg', np.stack([fixed[0], movingN[0], np.zeros(fixed[0].shape, dtype='int')], axis=-1))\n",
    "    cv2.imwrite('masktest2.jpg', np.stack([fixed[1], movingN[1], np.zeros(fixed[1].shape, dtype='int')], axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90611b1-a086-4169-89b9-ad256877d7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
